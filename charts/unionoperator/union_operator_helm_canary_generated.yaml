---
# Source: union-operator/templates/namespaces.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: flytesnacks-development
---
# Source: union-operator/templates/namespaces.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: flytesnacks-staging
---
# Source: union-operator/templates/namespaces.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: flytesnacks-production
---
# Source: union-operator/charts/union/templates/propeller/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flytepropeller
  namespace: union
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
  annotations: 
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
---
# Source: union-operator/charts/union/templates/propeller/webhook.yaml
# Create a Service Account for webhook
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flyte-pod-webhook
  namespace: union
---
# Source: union-operator/templates/cluster-resource-sync.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: clustersync-resource
  namespace: union
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: union-operator/templates/monitoring/dcgm-exporter/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dcgm-exporter
  namespace: kube-system
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: dcgm-exporter
    app.kubernetes.io/instance: union-operator-dcgm-exporter
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: union-operator/templates/monitoring/kube-state-metrics/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-state-metrics
  namespace: kube-system
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: union-operator-kube-state-metrics
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: union-operator/templates/monitoring/prometheus/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: union-operator-prometheus
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: union-operator/templates/objectstore/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: union-operator-object-store
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-object-store
    app.kubernetes.io/instance: union-operator-object-store
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "v0.0.1"
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
---
# Source: union-operator/templates/serviceaccount-proxy.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: union-operator-proxy
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: union-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
---
# Source: union-operator/charts/union/templates/common/secret-auth.yaml
apiVersion: v1
kind: Secret
metadata:
  name: flyte-secret-auth
  namespace: union
type: Opaque
stringData:
  client_secret: 'ghijklm'
---
# Source: union-operator/charts/union/templates/propeller/webhook.yaml
# Create an empty secret that the first propeller pod will populate
apiVersion: v1
kind: Secret
metadata:
  name: flyte-pod-webhook
  namespace: union
type: Opaque
---
# Source: union-operator/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: union-operator
type: Opaque
stringData:
  app_secret: ghijklm
---
# Source: union-operator/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: union-operator-cluster-name
type: Opaque
data:
  cluster_name: "Y2x1c3Rlcm5hbWU="
---
# Source: union-operator/templates/secret.yaml
# Secrets are required for syncresources, even if running standalone. Add empty secrets until resolved.
apiVersion: v1
kind: Secret
metadata:
  name: flyte-admin-secrets
type: Opaque
---
# Source: union-operator/charts/union/templates/clusterresourcesync/cluster_resource_configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: clusterresource-template
  namespace: union
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  a_namespace.yaml.yaml: | 
    apiVersion: v1
    kind: Namespace
    metadata:
      name: {{ namespace }}
      labels:
        union.ai/namespace-type: flyte
    spec:
      finalizers:
      - kubernetes
    
  b_default_service_account.yaml.yaml: | 
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: default
      namespace: {{ namespace }}
      annotations:
        {{ defaultUserRoleKey }}: {{ defaultUserRoleValue }}
    
  c_project_resource_quota.yaml.yaml: | 
    apiVersion: v1
    kind: ResourceQuota
    metadata:
      name: project-quota
      namespace: {{ namespace }}
    spec:
      hard:
        limits.cpu: {{ projectQuotaCpu }}
        limits.memory: {{ projectQuotaMemory }}
        requests.nvidia.com/gpu: {{ projectQuotaNvidiaGpu }}
---
# Source: union-operator/charts/union/templates/clusterresourcesync/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flyte-clusterresourcesync-config
  namespace: union
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  cluster_resources.yaml: | 
    cluster_resources:
      customData:
      - production:
        - projectQuotaCpu:
            value: "4096"
        - projectQuotaMemory:
            value: 2Ti
        - projectQuotaNvidiaGpu:
            value: "256"
        - defaultUserRoleKey:
            value: 'foo'
        - defaultUserRoleValue:
            value: 'bar'
      - staging:
        - projectQuotaCpu:
            value: "4096"
        - projectQuotaMemory:
            value: 2Ti
        - projectQuotaNvidiaGpu:
            value: "256"
        - defaultUserRoleKey:
            value: 'foo'
        - defaultUserRoleValue:
            value: 'bar'
      - development:
        - projectQuotaCpu:
            value: "4096"
        - projectQuotaMemory:
            value: 2Ti
        - projectQuotaNvidiaGpu:
            value: "256"
        - defaultUserRoleKey:
            value: 'foo'
        - defaultUserRoleValue:
            value: 'bar'
      refreshInterval: 5m
      standaloneDeployment: true
      templatePath: /etc/flyte/clusterresource/templates
  admin.yaml: | 
    admin:
      clientId: 'abcdef'
      clientSecretLocation: /etc/secrets/client_secret
      endpoint: 'dns:///playground.hosted.unionai.cloud'
      insecure: false
    event:
      capacity: 1000
      rate: 500
      type: admin
  domain.yaml: | 
    domains:
    - id: development
      name: development
    - id: staging
      name: staging
    - id: production
      name: production
  clusters.yaml: |
    clusters:
      clusterConfigs: []
      labelClusterMap: {}
---
# Source: union-operator/charts/union/templates/propeller/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flyte-propeller-config
  namespace: union
  labels: 
    app.kubernetes.io/name: flyteadmin
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
data:
  admin.yaml: | 
    admin:
      clientId: 'abcdef'
      clientSecretLocation: /etc/secrets/client_secret
      endpoint: 'dns:///playground.hosted.unionai.cloud'
      insecure: false
    event:
      capacity: 1000
      rate: 500
      type: admin
  catalog.yaml: | 
    catalog-cache:
      endpoint: 'dns:///playground.hosted.unionai.cloud'
      insecure: false
      type: datacatalog
      use-admin-auth: true
  copilot.yaml: | 
    plugins:
      k8s:
        co-pilot:
          image: public.ecr.aws/unionai-flyte/flytecopilot:52845ec8c96be193aee997b9b6909fa15d809e30
          name: flyte-copilot-
          start-timeout: 30s
  core.yaml: | 
    cache:
      max_size_mbs: 1024
      target_gc_percent: 70
    manager:
      pod-application: flytepropeller
      pod-template-container-name: flytepropeller
      pod-template-name: flytepropeller-template
      shard:
        shard-count: 3
        type: Hash
    propeller:
      downstream-eval-duration: 30s
      enable-admin-launcher: true
      event-config:
        raw-output-policy: inline
      gc-interval: 12h
      kube-client-config:
        burst: 25
        qps: 100
        timeout: 30s
      leader-election:
        enabled: false
        lease-duration: 15s
        lock-config-map:
          name: propeller-leader
          namespace: flyte
        renew-deadline: 10s
        retry-period: 2s
      limit-namespace: all
      max-workflow-retries: 50
      metadata-prefix: metadata/propeller
      metrics-prefix: flyte
      prof-port: 10254
      queue:
        batch-size: -1
        batching-interval: 1s
        queue:
          base-delay: 0s
          capacity: 10000
          max-delay: 60s
          rate: 1000
          type: maxof
        sub-queue:
          capacity: 10000
          rate: 1000
          type: bucket
        type: batch
      rawoutput-prefix: 's3://opencompute-staging-sample-tenant'
      workers: 100
      workflow-reeval-duration: 30s
    webhook:
      certDir: /etc/webhook/certs
      serviceName: flyte-pod-webhook
  enabled_plugins.yaml: | 
    tasks:
      task-plugins:
        default-for-task-types:
          container: container
          container_array: k8s-array
          sidecar: sidecar
        enabled-plugins:
        - container
        - sidecar
        - k8s-array
  k8s.yaml: | 
    plugins:
      k8s:
        default-cpus: 100m
        default-env-vars: []
        default-memory: 100Mi
  logger.yaml: | 
    logger:
      level: 4
      show-source: true
  resource_manager.yaml: | 
    propeller:
      resourcemanager:
        type: noop
  storage.yaml: | 
    storage:
      type: s3
      container: "opencompute-staging-sample-tenant"
      connection:
        auth-type: iam
        region: us-east-2
      enable-multicontainer: false
      limits:
        maxDownloadMBs: 10
  cache.yaml: |
    cache:
      max_size_mbs: 0
      target_gc_percent: 70
  task_logs.yaml: | 
    plugins:
      logs:
        cloudwatch-enabled: false
        kubernetes-enabled: true
---
# Source: union-operator/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: |
    union:
      connection:
        host: dns:///playground.hosted.unionai.cloud
      auth:
        type: ClientSecret
        clientId: abcdef
        clientSecretLocation: /etc/union/secret/app_secret
        authorizationMetadataKey: "flyte-authorization"
        tokenRefreshWindow: 5m
    operator:
      enabled: true
      enableTunnelService: true
      clusterId:
        organization: playground
      dependenciesHeartbeat:
        propeller:
          endpoint: http://flytepropeller.union.svc.cluster.local:10254
        proxy:
          endpoint: http://union-operator-proxy.union.svc.cluster.local:10254
        prometheus:
          endpoint: http://union-operator-prometheus.union.svc.cluster.local:80/prometheus/-/healthy
      clusterData:
        appId: abcdef
        cloudHostName: playground.hosted.unionai.cloud
        metadataBucketPrefix: s3://opencompute-staging-sample-tenant
        bucketName:  opencompute-staging-sample-tenant
        bucketRegion: us-east-2
        userRoleKey: foo
        userRole: bar
        storageType: s3
        gcpProjectId: dummy-gcs-projectId
      collectUsages:
        enabled: true
  logger.yaml: |
    logger:
      level: 4
      show-source: true
  storage.yaml: | 
    storage:
      type: s3
      container: "opencompute-staging-sample-tenant"
      connection:
        auth-type: iam
        region: us-east-2
      enable-multicontainer: false
      limits:
        maxDownloadMBs: 10
---
# Source: union-operator/templates/monitoring/prometheus/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: union-operator-prometheus
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
data:
  prometheus.yml: |
    global:
      scrape_interval:     15s
      evaluation_interval: 15s
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
    rule_files:
      - rules.yml
    scrape_configs:
      - job_name: 'prometheus'
        metrics_path: /prometheus/metrics
        static_configs:
        - targets: ['localhost:9090']
        metric_relabel_configs:
        - source_labels: [__name__]
          regex: prometheus_tsdb_head_chunks_storage_size_bytes|prometheus_tsdb_head_series|prometheus_tsdb_head_series_created_total|prometheus_tsdb_head_series_removed_total|prometheus_tsdb_head_samples_appended_total|prometheus_tsdb_storage_blocks_bytes|prometheus_tsdb_retention_limit_bytes|prometheus_tsdb_wal_storage_size_bytes
          action: keep
      - job_name: 'karpenter'
        scrape_interval: 30s
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - source_labels:
          - __meta_kubernetes_namespace
          - __meta_kubernetes_service_name
          - __meta_kubernetes_endpoint_port_name
          action: keep
          regex: karpenter;karpenter;http-metrics
        metric_relabel_configs:
        - source_labels: [__name__]
          regex: 'karpenter_pods_state'
          action: drop
        - source_labels: [__name__]
          # Remove metrics created per AWS instance type
          regex: karpenter_cloudprovider_instance_type_.*
          action: drop
      - job_name: 'kube-state-metrics'
        static_configs:
        - targets: ['kube-state-metrics.kube-system.svc.cluster.local:8080']
        metric_relabel_configs:
        - separator: ;
          source_labels: [__name__]
          regex: kube_pod_container_resource_(limits|requests)|kube_pod_status_phase|kube_node_(labels|status_condition)|kube_namespace_labels|kube_pod_container_status_(waiting|terminated).*
          action: keep
        - separator: ;
          source_labels: [__name__, phase]
          regex: kube_pod_status_phase;(Succeeded|Failed)
          action: drop
        # Drop select Flyte Pod metrics to mitiggate high cardinality.
        - separator: ;
          source_labels: [__name__, pod]
          regex: '(kube_pod_container_status_(waiting|terminated).*);[a-zA-Z0-9]+-n[0-9]+-[0-9]+.*$'
          action: drop
        # Consolidate AWS node groups and GCP node pools
        - source_labels: [label_node_group_name]
          target_label: label_group_name
          regex: '(.*)'  # copy the value as is
          action: replace
        - source_labels: [label_node_pool_name]
          target_label: label_group_name
          regex: '(.*)'  # copy the value as is
          action: replace
        - source_labels: [label_node_group_name, label_node_pool_name]
          target_label: label_group_name
          regex: '.*'  # fallback case when both labels are missing
          replacement: 'unknown'
          action: replace
        # Replace insert nodename to assist Grafana joins
        - source_labels: [node]
          target_label: nodename
          regex: '(.*)'  # copy the value as is
          action: replace
      - job_name: 'gpu-metrics'
        static_configs:
        - targets: ['dcgm-exporter.kube-system.svc.cluster.local:9400']
      - job_name: kubernetes-cadvisor
        metrics_path: /metrics
        scheme: https
        kubernetes_sd_configs:
        - api_server: null
          role: node
          namespaces:
            names: []
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: false
        metric_relabel_configs:
        - separator: ;
          source_labels: [__name__]
          regex: container_cpu_usage_seconds_total|container_memory_working_set_bytes|container_spec_memory_limit_bytes
          action: keep
        relabel_configs:
        - separator: ;
          regex: __meta_kubernetes_node_label_(.+)
          replacement: $1
          action: labelmap
        - separator: ;
          regex: (.*)
          target_label: __address__
          replacement: kubernetes.default.svc:443
          action: replace
        - source_labels: [__meta_kubernetes_node_name]
          separator: ;
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
          action: replace
      - job_name: 'union-metrics'
        static_configs:
        - targets: ['union-operator.union.svc.cluster.local']
      - job_name: 'fluentbit'
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - "kube-system"
          selectors:
          - role: "pod"
            label: "app.kubernetes.io/name=aws-for-fluent-bit"
        relabel_configs:
        - source_labels: [__metrics_path__]
          target_label: __metrics_path__
          replacement: /api/v1/metrics/prometheus
        - source_labels: [__address__]
          target_label: __address__
          action: replace
          regex: ([^:]+)(?::\d+)?
          replacement: $1:2020
        - source_labels: [__address__]
          regex: '(.*):\d+'
          target_label: instance
          replacement: '$1'
        - regex: pod
          action: labeldrop
        metric_relabel_configs:
        - source_labels: [__name__]
          regex: "fluentbit_input_bytes_total|\
            fluentbit_output_proc_records_total|\
            fluentbit_output_dropped_records_total|\
            fluentbit_output_proc_bytes_total"
          action: keep
      - job_name: 'node-exporter'
        scrape_interval: 60s
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - "kube-system"
          selectors:
          - role: "pod"
            label: "app.kubernetes.io/name=prometheus-node-exporter"
        relabel_configs:
        - source_labels: [__address__]
          target_label: __address__
          action: replace
          regex: ([^:]+)(?::\d+)?
          replacement: $1:9100
        - source_labels: [__address__]
          regex: '(.*):\d+'
          target_label: instance
          replacement: '$1'
        - regex: pod
          action: labeldrop
        metric_relabel_configs:
        - source_labels: [__name__]
          regex: 'node_cpu_guest_seconds_total|node_filesystem.*|node_network.*'
          action: drop
      - job_name: 'coredns'
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - "kube-system"
          selectors:
          - role: "pod"
            label: "eks.amazonaws.com/component=coredns"
        relabel_configs:
        - source_labels: [__address__]
          target_label: __address__
          action: replace
          regex: ([^:]+)(?::\d+)?
          replacement: $1:9153
        - source_labels: [__address__]
          regex: '(.*):\d+'
          target_label: instance
          replacement: '$1'
        metric_relabel_configs:
        - source_labels: [__name__]
          regex: "coredns_panics_total|\
            coredns_dns_requests_total|\
            coredns_dns_request_duration_seconds.*|\
            coredns_dns_responses_total"
          action: keep
      - job_name: 'kubernetes-apiservers'
        scrape_interval: 30s
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: false
        relabel_configs:
        - source_labels:
          - __meta_kubernetes_namespace
          - __meta_kubernetes_service_name
          - __meta_kubernetes_endpoint_port_name
          action: keep
          regex: default;kubernetes;https
        metric_relabel_configs:
        - action: replace
          source_labels: [resource]
          target_label: 'resource'
          replacement: 'union_cloud_replacement'
          regex: 'workqueue_.*'
        - action: keep
          regex: (apiserver_request_.*|apiserver_response_.*|workqueue_.*);(pods|nodes|union_cloud_replacement)
          source_labels:
          - __name__
          - resource
  rules.yml: |
    groups:
      - name: rollup
        rules:
        - record: instance_type:kube_node_labels:sum
          expr: sum by (label_cloud_google_com_gke_accelerator, label_cloud_google_com_gke_preemptible, label_eks_amazonaws_com_capacity_type, label_flyte_org_node_role, label_node_group_name, label_node_kubernetes_io_instance_type, label_node_pool_name, label_topology_kubernetes_io_region) (kube_node_labels{job="kube-state-metrics"})
        - record: phase:kube_pod_status_phase:sum
          expr: sum by (label_union_ai_namespace_type, phase) (kube_pod_status_phase{job="kube-state-metrics"} * on (namespace) group_left(label_union_ai_namespace_type) kube_namespace_labels)
        - record: namespace_phase:kube_pod_status_phase:sum
          expr: sum by (namespace, label_union_ai_namespace_type, phase) (kube_pod_status_phase{job="kube-state-metrics"} * on (namespace) group_left(label_union_ai_namespace_type) kube_namespace_labels)
        - record: namespace_type:pod:container_cpu_usage_seconds_total:count
          expr: count by (label_union_ai_namespace_type) (count  by (namespace, label_union_ai_namespace_type, pod) (container_cpu_usage_seconds_total{pod!="", job="kubernetes-cadvisor", name!=""} * on (namespace) group_left(label_union_ai_namespace_type) kube_namespace_labels))
        - record: namespace:pod:container_cpu_usage_seconds_total:count
          expr: count by (namespace, label_union_ai_namespace_type) (count  by (namespace, label_union_ai_namespace_type, pod) (container_cpu_usage_seconds_total{pod!="", job="kubernetes-cadvisor", name!=""} * on (namespace) group_left(label_union_ai_namespace_type) kube_namespace_labels))
        - record: pod:container_cpu_usage_seconds_total:sum
          expr: sum by (namespace, pod) (container_cpu_usage_seconds_total{namespace=~"union|kube-system", image!="", job="kubernetes-cadvisor", name!=""})
        - record: pod:container_memory_working_set_bytes:sum
          expr: sum by (namespace, pod) (container_memory_working_set_bytes{namespace=~"union|kube-system", image!="", job="kubernetes-cadvisor", name!=""})
        - record: pod:container_spec_memory_limit_bytes:sum
          expr: sum by (namespace, pod) (container_spec_memory_limit_bytes{namespace=~"union|kube-system", image!="", job="kubernetes-cadvisor", name!=""})
        - record: container:container_memory_working_set_bytes:sum
          expr: sum by (namespace, pod, name) (container_memory_working_set_bytes{namespace=~"union|kube-system", image!="", job="kubernetes-cadvisor", name!=""})
        - record: container:container_spec_memory_limit_bytes:sum
          expr: sum by (namespace, pod, name) (container_spec_memory_limit_bytes{namespace=~"union|kube-system", image!="", job="kubernetes-cadvisor", name!=""})
        - record: pod:kube_pod_container_resource_requests:sum
          expr: sum by (namespace, pod, resource) (kube_pod_container_resource_requests{namespace=~"union|kube-system", resource=~"cpu|memory", job="kube-state-metrics"})
        - record: pod:kube_pod_container_resource_limits:sum
          expr: sum by (namespace, pod, resource) (kube_pod_container_resource_limits{namespace=~"union|kube-system", resource=~"cpu|memory", job="kube-state-metrics"})
        - record: job:up:sum
          expr: sum by (job) (up)
        - record: job:up:count
          expr: count by (job) (up)
        - record: flyte_agent_request_latency_seconds:mean1m
          expr: sum(rate(flyte_agent_request_latency_seconds_sum[1m])) / sum(rate(flyte_agent_request_latency_seconds_count[1m]))
        - record: name:time_series_cardinality:count
          expr: sum by (name)(label_replace(count by(__name__) ({__name__=~".+"}), "name", "$1", "__name__", "(.+)"))
        # Fluentbit Rules
        - record: fluentbit_input_bytes_total:sum
          expr: sum(fluentbit_input_bytes_total)
        - record: fluentbit_output_dropped_records_total:sum
          expr: sum(fluentbit_output_dropped_records_total)
        - record: fluentbit_output_proc_bytes_total:sum
          expr: sum(fluentbit_output_proc_bytes_total)
        - record: instance:fluentbit_output_proc_records_total:rate_sum
          expr: sum by(instance)(rate(fluentbit_output_proc_records_total[2m]))
        # Node-exporter rules
        # Copied from kube-prometheus-stack rules, can be remove and switch the Prometheus Operator CRD managed rules
        # Reference: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/node-exporter.rules.yaml#L67
        - record: ethtool:conntrack_allowance_exceeded:sum
          expr: sum(node_ethtool_conntrack_allowance_exceeded)
        - record: instance:node_num_cpu:sum
          expr: |-
            count without (cpu, mode) (
              node_cpu_seconds_total{job="node-exporter",mode="idle"}
            )
        - record: instance:node_cpu_utilisation:rate5m
          expr: |-
            1 - avg without (cpu) (
              sum without (mode) (rate(node_cpu_seconds_total{job="node-exporter", mode=~"idle|iowait|steal"}[5m]))
            )
        - record: instance:node_load1_per_cpu:ratio
          expr: |-
            (
              node_load1{job="node-exporter"}
            /
              instance:node_num_cpu:sum{job="node-exporter"}
            )
        - record: instance:node_memory_utilisation:ratio
          expr: |-
            1 - (
              node_memory_MemAvailable_bytes{job="node-exporter"}
            /
              node_memory_MemTotal_bytes{job="node-exporter"}
            )
        - record: instance:node_vmstat_pgmajfault:rate5m
          expr: rate(node_vmstat_pgmajfault{job="node-exporter"}[5m])
---
# Source: union-operator/charts/union/templates/propeller/crds/flyteworkflow.yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: flyteworkflows.flyte.lyft.com
spec:
  group: flyte.lyft.com
  names:
    kind: FlyteWorkflow
    plural: flyteworkflows
    shortNames:
      - fly
    singular: flyteworkflow
  scope: Namespaced
  versions:
    - name: v1alpha1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          x-kubernetes-preserve-unknown-fields: true
          properties:
---
# Source: union-operator/charts/union/templates/propeller/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: union-flytepropeller
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
rules:
# Allow RO access to PODS
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
# Allow Event recording access
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - update
  - delete
  - patch
# Allow Access All plugin objects
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - delete
  - patch
# Allow Access to CRD
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
# Allow Access to all resources under flyte.lyft.com
- apiGroups:
  - flyte.lyft.com
  resources:
  - flyteworkflows
  - flyteworkflows/finalizers
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - delete
  - patch
  - post
  - deletecollection
---
# Source: union-operator/charts/union/templates/propeller/webhook.yaml
# Create a ClusterRole for the webhook
# https://kubernetes.io/docs/admin/authorization/rbac/
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: union-flyte-pod-webhook
  namespace: union
rules:
  - apiGroups:
      - "*"
    resources:
      - mutatingwebhookconfigurations
      - secrets
      - pods
      - replicasets/finalizers
    verbs:
      - get
      - create
      - update
      - patch
---
# Source: union-operator/templates/cluster-resource-sync.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: clustersync-resource
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
      - rbac.authorization.k8s.io
    resources:
      - configmaps
      - namespaces
      - pods
      - resourcequotas
      - roles
      - rolebindings
      - secrets
      - services
      - serviceaccounts
    verbs:
      - '*'
---
# Source: union-operator/templates/monitoring/kube-state-metrics/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kube-state-metrics
rules:
  - apiGroups: [""]
    resources:
      - namespaces
      - nodes
      - pods
    verbs: ["get", "list", "watch"]
---
# Source: union-operator/templates/monitoring/prometheus/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: union-operator-prometheus
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - '*'
    resources:
      - nodes
      - nodes/proxy
      - pods
      - endpoints
      - services
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - /metrics
      - /metrics/cadvisor
    verbs:
      - get
---
# Source: union-operator/templates/serviceaccount-proxy.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: union-operator-proxy
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - '*'
    resources:
      - flyteworkflows
      - pods/log
      - pods
      - rayjobs
      - resourcequotas
    verbs:
      - get
      - list
      - watch
---
# Source: union-operator/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
rules:
  # Allow Access to all resources under flyte.lyft.com
  - apiGroups:
      - flyte.lyft.com
    resources:
      - flyteworkflows
      - flyteworkflows/finalizers
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - delete
      - patch
      - post
      - deletecollection
  - apiGroups:
      - '*'
    resources:
      - resourcequotas
      - pods
      - configmaps
      - podtemplates
      - nodes
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - delete
---
# Source: union-operator/charts/union/templates/propeller/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: union-flytepropeller
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: union-flytepropeller
subjects:
- kind: ServiceAccount
  name: flytepropeller
  namespace: union
---
# Source: union-operator/charts/union/templates/propeller/webhook.yaml
# Create a binding from Role -> ServiceAccount
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: union-flyte-pod-webhook
  namespace: union
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: union-flyte-pod-webhook
subjects:
  - kind: ServiceAccount
    name: flyte-pod-webhook
    namespace: union
---
# Source: union-operator/templates/cluster-resource-sync.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: clustersync-resource
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: clustersync-resource
subjects:
  - kind: ServiceAccount
    name: clustersync-resource
    namespace: union
---
# Source: union-operator/templates/monitoring/kube-state-metrics/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-state-metrics
subjects:
  - kind: ServiceAccount
    name: kube-state-metrics
    namespace: kube-system
---
# Source: union-operator/templates/monitoring/prometheus/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: union-operator-prometheus
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: union-operator-prometheus
subjects:
  - kind: ServiceAccount
    name: union-operator-prometheus
    namespace: union
---
# Source: union-operator/templates/objectstore/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: union-operator-object-store
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-object-store
    app.kubernetes.io/instance: union-operator-object-store
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "v0.0.1"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
  - kind: ServiceAccount
    name: union-operator-object-store
    namespace: union
---
# Source: union-operator/templates/serviceaccount-proxy.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: union-operator-proxy
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: union-operator-proxy
subjects:
  - kind: ServiceAccount
    name: union-operator-proxy
    namespace: union
---
# Source: union-operator/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: union-operator
subjects:
  - kind: ServiceAccount
    name: union-operator
    namespace: union
---
# Source: union-operator/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
rules:
  - apiGroups:
      - '*'
    resources:
      - secrets
      - deployments
    verbs:
      - get
      - list
      - watch
      - create
      - update
---
# Source: union-operator/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::479331373192:role/opencompute-staging-sample-tenant-adminflyterole
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: union-operator
subjects:
  - kind: ServiceAccount
    name: union-operator
    namespace: union
---
# Source: union-operator/charts/union/templates/propeller/webhook.yaml
# Service
apiVersion: v1
kind: Service
metadata:
  name: flyte-pod-webhook
  namespace: union
  annotations: 
    projectcontour.io/upstream-protocol.h2c: grpc
spec:
  selector:
    app: flyte-pod-webhook
  ports:
    - name: https
      protocol: TCP
      port: 443
      targetPort: 9443
---
# Source: union-operator/templates/monitoring/dcgm-exporter/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: dcgm-exporter
  namespace: kube-system
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: dcgm-exporter
    app.kubernetes.io/instance: union-operator-dcgm-exporter
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "dcgm-exporter"
spec:
  type: ClusterIP
  ports:
    - port: 9400
      targetPort:  9400
      protocol: TCP
      name: "metrics"
  selector:
    app.kubernetes.io/name: dcgm-exporter
    app.kubernetes.io/instance: union-operator-dcgm-exporter
---
# Source: union-operator/templates/monitoring/kube-state-metrics/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-state-metrics
  namespace: kube-system
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: union-operator-kube-state-metrics
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort:  8080
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: union-operator-kube-state-metrics
---
# Source: union-operator/templates/monitoring/prometheus/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: union-operator-prometheus
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort:  9090
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
---
# Source: union-operator/templates/service-proxy.yaml
apiVersion: v1
kind: Service
metadata:
  name: union-operator-proxy
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-proxy
    app.kubernetes.io/instance: union-operator-proxy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "v0.0.1"
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
    - port: 10254
      targetPort: debug
      protocol: TCP
      name: debug
  selector:
    app.kubernetes.io/name: union-operator-proxy
    app.kubernetes.io/instance: union-operator-proxy
---
# Source: union-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: debug
      protocol: TCP
      name: debug
  selector:
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
---
# Source: union-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: flytepropeller
spec:
  ports:
    - port: 10254
  selector:
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: union-operator
---
# Source: union-operator/templates/monitoring/dcgm-exporter/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: dcgm-exporter
  namespace: kube-system
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: dcgm-exporter
    app.kubernetes.io/instance: union-operator-dcgm-exporter
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "dcgm-exporter"
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: dcgm-exporter
      app.kubernetes.io/instance: union-operator-dcgm-exporter
      app.kubernetes.io/component: "dcgm-exporter"
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/name: dcgm-exporter
        app.kubernetes.io/instance: union-operator-dcgm-exporter
        app.kubernetes.io/component: "dcgm-exporter"
    spec:
      priorityClassName: system-node-critical
      serviceAccountName: dcgm-exporter
      securityContext:
        {}
      volumes:
        - name: "pod-gpu-resources"
          hostPath:
            path: /var/lib/kubelet/pod-resources
        - name: "nvidia-install-dir-host"
          hostPath:
            path: "/home/kubernetes/bin/nvidia"
      containers:
        - name: exporter
          image: "nvcr.io/nvidia/k8s/dcgm-exporter:3.1.7-3.1.4-ubuntu20.04"
          imagePullPolicy: IfNotPresent
          securityContext:
            capabilities:
              add:
              - SYS_ADMIN
            privileged: true
            runAsNonRoot: false
            runAsUser: 0
          args:
          - -f
          - /etc/dcgm-exporter/dcp-metrics-included.csv
          env:
            - name: "DCGM_EXPORTER_KUBERNETES"
              value: "true"
            - name: "DCGM_EXPORTER_LISTEN"
              value: ":9400"
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          ports:
            - name: "metrics"
              containerPort: 9400
          volumeMounts:
            - name: "pod-gpu-resources"
              readOnly: true
              mountPath: "/var/lib/kubelet/pod-resources"
            - mountPath: /usr/local/nvidia
              name: nvidia-install-dir-host
              readOnly: true
          livenessProbe:
            httpGet:
              path: /health
              port: 9400
            initialDelaySeconds: 45
            periodSeconds: 5
          readinessProbe:
            httpGet:
              path: /health
              port: 9400
            initialDelaySeconds: 45
          resources:
            limits:
              ephemeral-storage: 500Mi
              memory: 400Mi
            requests:
              cpu: 100m
              ephemeral-storage: 500Mi
              memory: 128Mi
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: ami_type
                operator: In
                values:
                - AL2_x86_64_GPU
            - matchExpressions:
              - key: cloud.google.com/gke-accelerator
                operator: Exists
      tolerations:
        - effect: NoSchedule
          key: nvidia.com/gpu
          operator: Exists
        - effect: NoSchedule
          key: flyte.org/node-role
          operator: Exists
---
# Source: union-operator/charts/union/templates/clusterresourcesync/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: syncresources
  namespace: union
  labels: 
    app.kubernetes.io/name: flyteclusterresourcesync
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/name: flyteclusterresourcesync
      app.kubernetes.io/instance: union-operator
  template:
    metadata:
      annotations:
        configChecksum: "f349b9998d56456d2ea22803ea3bf3a140c8a95c26b2a7a8f5316ddbd4e6695"
      labels: 
        app.kubernetes.io/name: flyteclusterresourcesync
        app.kubernetes.io/instance: union-operator
        helm.sh/chart: union-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      containers:
        - command:
            - flyteadmin
            - --config
            - /etc/flyte/config/*.yaml
            - clusterresource
            - run
          image: "public.ecr.aws/unionai-flyte/flyteadmin:52845ec8c96be193aee997b9b6909fa15d809e30"
          imagePullPolicy: "IfNotPresent"
          name: sync-cluster-resources
          volumeMounts:
          - name: auth
            mountPath: /etc/secrets/
          - mountPath: /etc/flyte/clusterresource/templates
            name: resource-templates
          - mountPath: /etc/flyte/config
            name: config-volume
      serviceAccountName: clustersync-resource
      volumes:
        
        - configMap:
            name: clusterresource-template
          name: resource-templates
        - configMap:
            name: flyte-clusterresourcesync-config
          name: config-volume
        - name: auth
          secret:
            secretName: flyte-secret-auth
---
# Source: union-operator/charts/union/templates/propeller/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: union
  name: flytepropeller
  labels: 
    app.kubernetes.io/name: flytepropeller
    app.kubernetes.io/instance: union-operator
    helm.sh/chart: union-v0.1.10
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels: 
      app.kubernetes.io/name: flytepropeller
      app.kubernetes.io/instance: union-operator
  template:
    metadata:
      annotations:
        configChecksum: "de675216313f0abe5e1d505bc4f8eb6051e90f2b919e773ba94153dacf95615"
      labels: 
        app.kubernetes.io/name: flytepropeller
        app.kubernetes.io/instance: union-operator
        helm.sh/chart: union-v0.1.10
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 65534
        runAsUser: 1001
        fsGroupChangePolicy: "Always"
      priorityClassName: system-cluster-critical
      containers:
      - command:
        - flytepropeller
        - --config
        - /etc/flyte/config/*.yaml
        - --propeller.cluster-id
        - 'clustername'
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: "public.ecr.aws/p0i0a9q8/unionoperator:invalid-version"
        imagePullPolicy: "IfNotPresent"
        name: flytepropeller
        ports:
        - containerPort: 10254
        resources:
          limits:
            cpu: "4"
            ephemeral-storage: 500Mi
            memory: 8Gi
          requests:
            cpu: 3400m
            ephemeral-storage: 100Mi
            memory: 4Gi
        volumeMounts:
        - name: config-volume
          mountPath: /etc/flyte/config
        - name: auth
          mountPath: /etc/secrets/
        terminationMessagePolicy: "FallbackToLogsOnError"
      serviceAccountName: flytepropeller
      volumes:
      - configMap:
          name: flyte-propeller-config
        name: config-volume
      - name: auth
        secret:
          secretName: flyte-secret-auth
---
# Source: union-operator/charts/union/templates/propeller/webhook.yaml
# Create the actual deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flyte-pod-webhook
  namespace: union
  labels:
    app: flyte-pod-webhook
spec:
  selector:
    matchLabels:
      app: flyte-pod-webhook
  template:
    metadata:
      labels:
        app: flyte-pod-webhook
        app.kubernetes.io/name: flyte-pod-webhook
        app.kubernetes.io/version: invalid-version
      annotations:
        configChecksum: "de675216313f0abe5e1d505bc4f8eb6051e90f2b919e773ba94153dacf95615"
    spec:
      securityContext:
        fsGroup: 65534
        runAsNonRoot: true
        runAsUser: 1001
        fsGroupChangePolicy: "Always"
        seLinuxOptions:
          type: spc_t
      serviceAccountName: flyte-pod-webhook
      initContainers:
      - name: generate-secrets
        image: "public.ecr.aws/p0i0a9q8/unionoperator:invalid-version"
        imagePullPolicy: "IfNotPresent"
        command:
          - flytepropeller
        args:
          - webhook
          - init-certs
          - --config
          - /etc/flyte/config/*.yaml
        env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
          - name: config-volume
            mountPath: /etc/flyte/config
      containers:
        - name: webhook
          image: "public.ecr.aws/p0i0a9q8/unionoperator:invalid-version"
          imagePullPolicy: "IfNotPresent"
          command:
            - flytepropeller
          args:
            - webhook
            - --config
            - /etc/flyte/config/*.yaml
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
          - containerPort: 9443
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          volumeMounts:
            - name: config-volume
              mountPath: /etc/flyte/config
              readOnly: true
            - name: webhook-certs
              mountPath: /etc/webhook/certs
              readOnly: true
      volumes:
        - name: config-volume
          configMap:
            name: flyte-propeller-config
        - name: webhook-certs
          secret:
            secretName: flyte-pod-webhook
---
# Source: union-operator/templates/deployment-proxy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: union-operator-proxy
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-proxy
    app.kubernetes.io/instance: union-operator-proxy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "v0.0.1"
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: union-operator-proxy
      app.kubernetes.io/instance: union-operator-proxy
  template:
    metadata:
      annotations:
        prometheus.io/path: /metrics
        prometheus.io/port: "10254"
        prometheus.io/scrape: "true"
      labels:
        app.kubernetes.io/name: union-operator-proxy
        app.kubernetes.io/instance: union-operator-proxy
    spec:
      volumes:
        - name: config-volume
          projected:
            sources:
            - configMap:
                name: union-operator
            - configMap:
                name: flyte-clusterresourcesync-config
      priorityClassName: system-cluster-critical
      serviceAccountName: union-operator-proxy
      securityContext:
        {}
      containers:
        - name: union-operator-proxy
          securityContext:
            {}
          image: "public.ecr.aws/p0i0a9q8/unionoperator:invalid-tag"
          imagePullPolicy: IfNotPresent
          terminationMessagePolicy: FallbackToLogsOnError
          resources:
            limits:
              cpu: "1"
              ephemeral-storage: 500Mi
              memory: 1Gi
            requests:
              cpu: 100m
              ephemeral-storage: 100Mi
              memory: 128Mi
          volumeMounts:
            - mountPath: /etc/union/config
              name: config-volume
          args:
            - operator
            - proxy
            - --config
            - /etc/union/config/*.yaml
          ports:
            - name: http
              containerPort: 8089
              protocol: TCP
            - name: grpc
              containerPort: 8080
              protocol: TCP
            - name: debug
              containerPort: 10254
              protocol: TCP
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
---
# Source: union-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: union-operator
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator
    app.kubernetes.io/instance: union-operator
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: union-operator
      app.kubernetes.io/instance: union-operator
  template:
    metadata:
      annotations:
        configChecksum: "298eb846a498ff07322a3ec33da35940290d3a245152a0fa7d9848ac766ee23"
        prometheus.io/path: /metrics
        prometheus.io/port: "10254"
        prometheus.io/scrape: "true"
      labels:
        app.kubernetes.io/name: union-operator
        app.kubernetes.io/instance: union-operator
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: union-operator
      securityContext:
        {}
      volumes:
        - name: config-volume
          configMap:
            name: union-operator
        - name: secret-volume
          secret:
            secretName: union-operator
      containers:
        - name: union-operator
          securityContext:
            {}
          image: "public.ecr.aws/p0i0a9q8/unionoperator:invalid-tag"
          imagePullPolicy: IfNotPresent
          terminationMessagePolicy: FallbackToLogsOnError
          resources:
            limits:
              cpu: "4"
              ephemeral-storage: 500Mi
              memory: 8Gi
            requests:
              cpu: "1"
              ephemeral-storage: 100Mi
              memory: 4Gi
          volumeMounts:
            - mountPath: /etc/union/config
              name: config-volume
            - mountPath: /etc/union/secret
              name: secret-volume
          env:
            - name: CLUSTER_NAME
              valueFrom:
                secretKeyRef:
                  name: union-operator-cluster-name
                  key: cluster_name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: DEPLOYMENT_NAME
              value: union-operator
          args:
            - operator
            - serve
            - --config
            - /etc/union/config/*.yaml
            - --operator.clusterId.name
            - "$(CLUSTER_NAME)"
            - --operator.tunnel.k8sSecretName
            - union-operator
          ports:
            - name: grpc
              containerPort: 8080
              protocol: TCP
            - name: http
              containerPort: 8089
              protocol: TCP
            - name: debug
              containerPort: 10254
              protocol: TCP
        - name: "tunnel"
          securityContext:
            {}
          image: cloudflare/cloudflared:2023.10.0
          imagePullPolicy: IfNotPresent
          args:
            - tunnel
            - --no-autoupdate
            - run
            - --token
            - $(TUNNEL_TOKEN)
          env:
            - name: TUNNEL_TOKEN
              valueFrom:
                secretKeyRef:
                  name: union-operator
                  key: tunnel_token
                  optional: true
---
# Source: union-operator/templates/monitoring/kube-state-metrics/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-state-metrics
  namespace: kube-system
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: union-operator-kube-state-metrics
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/instance: union-operator-kube-state-metrics
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/instance: union-operator-kube-state-metrics
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: kube-state-metrics
      securityContext:
        {}
      containers:
        - args:
            - --port=8080
            - --resources=namespaces,nodes,pods
            - --metric-labels-allowlist=namespaces=[union.ai/namespace-type],nodes=[cloud.google.com/gke-accelerator,cloud.google.com/gke-preemptible,eks.amazonaws.com/capacityType,flyte.org/node-role,node.kubernetes.io/instance-type,node_group_name,node_pool_name,topology.kubernetes.io/region,topology.kubernetes.io/zone]
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: union-operator
          image: "registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.8.1"
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePolicy: FallbackToLogsOnError
          resources:
            limits:
              cpu: "4"
              ephemeral-storage: 500Mi
              memory: 8Gi
            requests:
              cpu: "1"
              ephemeral-storage: 100Mi
              memory: 500Mi
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
---
# Source: union-operator/templates/monitoring/prometheus/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: union-operator-prometheus
  labels:
    helm.sh/chart: union-operator-v0.0.1-local
    app.kubernetes.io/name: union-operator-prometheus
    app.kubernetes.io/instance: union-operator-prometheus
    app.kubernetes.io/version: "v0.0.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: union-operator-prometheus
      app.kubernetes.io/instance: union-operator-prometheus
  template:
    metadata:
      annotations:
        configChecksum: "02550ae046dad1c38679a7e6580d524aa9e61264160abb1f6cfc8d3ce3091ee"
      labels:
        app.kubernetes.io/name: union-operator-prometheus
        app.kubernetes.io/instance: union-operator-prometheus
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: union-operator-prometheus
      securityContext:
            fsGroup: 65534
            fsGroupChangePolicy: OnRootMismatch
            runAsNonRoot: true
            runAsUser: 65534
      volumes:
        - name: prometheus-config-volume
          configMap:
            name: 'union-operator-prometheus'
      containers:
        - args:
            - --config.file=/etc/prometheus/prometheus.yml
            - --web.external-url=/prometheus/
            - --web.route-prefix=/prometheus/
            - --storage.tsdb.retention.size=400MB
          image: "prom/prometheus:v2.43.0"
          imagePullPolicy: IfNotPresent
          name: union-operator
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePolicy: FallbackToLogsOnError
          resources:
            limits:
              cpu: "4"
              ephemeral-storage: 1Gi
              memory: 8Gi
            requests:
              cpu: "1"
              ephemeral-storage: 500Mi
              memory: 500Mi
          volumeMounts:
            - mountPath: /etc/prometheus
              name: prometheus-config-volume
          ports:
            - name: http
              containerPort: 18080
              protocol: TCP
